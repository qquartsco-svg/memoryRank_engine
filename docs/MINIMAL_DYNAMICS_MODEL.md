# ğŸ›ï¸ Cognitive Kernel v2.0.1 ìµœì†Œ ì°¨ë¶„ ëª¨ë¸

> **ì½”ë“œì™€ 1:1ë¡œ ëŒ€ì‘ë˜ëŠ” ìˆ˜í•™ì  ì •ì˜**

ì´ ëª¨ë¸ì€ ê²°ì • ìŠ¤í… $n$ì—ì„œ íšŒìƒëœ ê¸°ì–µì˜ ì¤‘ìš”ë„ì™€ í…ìŠ¤íŠ¸ ë§¤ì¹­ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œìŠ¤í…œ ì—”íŠ¸ë¡œí”¼($E_n$)ê°€ ê²°ì •ë˜ëŠ” ê³¼ì •ì„ ì •ì˜í•©ë‹ˆë‹¤.

---

## ğŸ“ ìƒíƒœë°©ì •ì‹

### 1. ê¸°ì–µ ê´€ë ¨ì„± ê³„ì‚°

$$
C_n(k) = \min\left(1, \sum_{i} s_i \cdot m_{i,k}\right)
$$

**ì½”ë“œ êµ¬í˜„:**
```python
# _calculate_memory_relevance()
total_relevance = 0.0
for mem in memories:
    importance = mem.get("importance", 0.0)  # s_i
    match_score = 0.0  # m_{i,k}
    for keyword in option_keywords:
        if keyword in content_text:
            match_score += 1.0 / len(option_keywords)
    total_relevance += importance * match_score  # s_i * m_{i,k}

return min(1.0, total_relevance)  # C_n(k)
```

**ì£¼ì˜:**
- í•˜í•œ 0 clampëŠ” ì½”ë“œì— ì—†ìŒ (ìŒìˆ˜ê°€ ë‚˜ì˜¬ ê²½ë¡œê°€ ì—†ì–´ì„œ ê²°ê³¼ëŠ” ë™ì¼)
- ì‹¤ì œ êµ¬í˜„: `min(1.0, total_relevance)`ë§Œ ìˆ˜í–‰

---

### 2. Utility ê³„ì‚°

$$
U_{n,k} = U_0 + \alpha \cdot C_n(k)
$$

**ì½”ë“œ êµ¬í˜„:**
```python
# decide() ë©”ì„œë“œ
alpha = 0.5  # ê¸°ì–µ ì˜í–¥ ê³„ìˆ˜
expected_reward = 0.5 + alpha * memory_relevance  # U_0 + Î± * C_n(k)
```

**ë³€ìˆ˜:**
- $U_0 = 0.5$: ê¸°ë³¸ ë³´ìƒ (ì½”ë“œ ë‚´ë¶€ ìƒìˆ˜)
- $\alpha = 0.5$: ê¸°ì–µ ì˜í–¥ ê³„ìˆ˜ (ì½”ë“œ ë‚´ë¶€ ìƒìˆ˜)

---

### 3. ì„ íƒ í™•ë¥  (PFC Softmax)

$$
P_n(k) = \frac{\exp(\beta \cdot U_{n,k})}{\sum_j \exp(\beta \cdot U_{n,j})}
$$

**ì½”ë“œ êµ¬í˜„:**
```python
# PFCEngine._softmax_probabilities()
beta = self.config.decision_temperature
exp_values = [math.exp(beta * (u - max_u)) for u in utilities]
total = sum(exp_values)
probs = [e / total for e in exp_values]
```

**ë³€ìˆ˜:**
- $\beta = \text{decision\_temperature}$: Inverse-temperature
- êµ¬í˜„ ì£¼ì²´: **PFCEngine.process(actions)** ë‚´ë¶€ softmax

---

### 4. ì‹œìŠ¤í…œ ì—”íŠ¸ë¡œí”¼

$$
E_n = -\sum_{k} P_n(k) \ln P_n(k)
$$

**ì˜ë¯¸:**
- ì„ íƒì˜ ë¶ˆí™•ì‹¤ì„± ë° íƒìƒ‰ë„
- $E_n \to 0$: ì €ì—”íŠ¸ë¡œí”¼ (ê²°ì •ë¡ ì , ìˆ˜ë ´)
- $E_n \to \ln(N)$: ê³ ì—”íŠ¸ë¡œí”¼ (ë¬´ì‘ìœ„, ë¶„ì‚°)

---

## ğŸ” ë³€ìˆ˜ ì •ì˜ (v2.0.1 êµ¬í˜„ ê¸°ì¤€)

| ë³€ìˆ˜ | ì •ì˜ | ì½”ë“œ ìœ„ì¹˜ |
|------|------|----------|
| $s_i$ | recall()ë¡œ ë°˜í™˜ëœ ê¸°ì–µ $i$ì˜ ì¤‘ìš”ë„ ì ìˆ˜ | MemoryRank score |
| $m_{i,k}$ | ì˜µì…˜ $k$ì˜ í‚¤ì›Œë“œê°€ ê¸°ì–µ $i$ì˜ payload í…ìŠ¤íŠ¸ì™€ ë§¤ì¹­ë˜ëŠ” ì •ë„ (0~1) | `_calculate_memory_relevance()` |
| $\beta$ | decision_temperature (Inverse-temperature) | `PFCConfig.decision_temperature` |
| $\alpha$ | ê¸°ì–µ ì˜í–¥ ê³„ìˆ˜ (ê¸°ë³¸ ë³´ìƒ $U_0$ì— ëŒ€í•œ ê¸°ì–µ ì¤‘ë ¥ì˜ ê°€ì¤‘ì¹˜) | `decide()` ë‚´ë¶€ ìƒìˆ˜ (0.5) |
| $U_0$ | ê¸°ë³¸ ë³´ìƒ | `decide()` ë‚´ë¶€ ìƒìˆ˜ (0.5) |
| $E_n$ | ì‹œìŠ¤í…œ ì—”íŠ¸ë¡œí”¼ (ì„ íƒì˜ ë¶ˆí™•ì‹¤ì„± ë° íƒìƒ‰ë„) | ê³„ì‚° ê°€ëŠ¥ |

---

## âš–ï¸ ëª¨ë“œë³„ ë™ì—­í•™ì  íŠ¹ì„±

### ASD (-): ì €ì—”íŠ¸ë¡œí”¼ ê³ ì°©

**íŒŒë¼ë¯¸í„°:**
- $\beta \uparrow$ (decision_temperature = 5.0)
- $\alpha = 0.5$ (ê¸°ì–µ ì˜í–¥ ê³„ìˆ˜)

**ë™ì—­í•™:**
$$
\beta \uparrow + \alpha C_n(k) \to U \text{ ê²©ì°¨ í™•ëŒ€} \to P \text{ ìˆ˜ë ´} \to E_n \to 0
$$

**ê²°ê³¼:**
- ì„ íƒ ë¶„í¬ $P$ê°€ íŠ¹ì • ì„ íƒì§€ë¡œ ìˆ˜ë ´
- ì—”íŠ¸ë¡œí”¼ $E_n \to 0$ (ì €ì—”íŠ¸ë¡œí”¼ ê³ ì°© ìƒíƒœ)

**ì½”ë“œ ê²€ì¦:**
- í…ŒìŠ¤íŠ¸ ê²°ê³¼: choose_red 90% (íŒ¨í„´ ê³ ì°©)
- ì„ íƒ ë¶„ì‚°: 2ê°œ ê³ ìœ  ì„ íƒ

---

### ADHD (+): ê³ ì—”íŠ¸ë¡œí”¼ ë°œì‚°

**íŒŒë¼ë¯¸í„°:**
- $\beta \downarrow$ (decision_temperature = 0.5)
- $\alpha = 0.5$ (ê¸°ì–µ ì˜í–¥ ê³„ìˆ˜)

**ë™ì—­í•™:**
$$
\beta \downarrow \to P \text{ í‰íƒ„í™”} \to E_n \to \ln(N)
$$

**ê²°ê³¼:**
- ì„ íƒ ë¶„í¬ $P$ê°€ í‰íƒ„í•´ì§
- ì—”íŠ¸ë¡œí”¼ $E_n \to \ln(N)$ (ê³ ì—”íŠ¸ë¡œí”¼ ë°œì‚° ìƒíƒœ)

**ì½”ë“œ ê²€ì¦:**
- í…ŒìŠ¤íŠ¸ ê²°ê³¼: choose_red 30% (ì‚°ë§Œí•¨)
- ì„ íƒ ë¶„ì‚°: 3ê°œ ê³ ìœ  ì„ íƒ

**ì£¼ì˜:**
- BasalGangliaì˜ `tau`, `impulsivity`, `patience`ëŠ” í˜„ì¬ `P_n(k)`ì— ì§ì ‘ ê°œì…í•˜ì§€ ì•ŠìŒ
- BasalGangliaëŠ” `habit_suggestion` ì±„ë„ë¡œë§Œ ì˜í–¥ (ì¶©ëŒ flag ê´€ì°° ê°€ëŠ¥)

---

## ğŸ”¬ ì½”ë“œ-ìˆ˜ì‹ 1:1 ëŒ€ì‘

### decide() ë©”ì„œë“œ ì‹¤í–‰ ê²½ë¡œ

```python
def decide(self, options: List[str], ...):
    # 1. ê¸°ì–µ íšŒìƒ
    memories = self.recall(k=5)  # s_i íšë“
    
    # 2. ê´€ë ¨ì„± ê³„ì‚°
    for opt in options:
        opt_keywords = self._extract_keywords(opt)
        memory_relevance = self._calculate_memory_relevance(opt_keywords, memories)
        # â†’ C_n(k) = min(1, Î£ s_i * m_{i,k})
    
    # 3. Utility ê³„ì‚°
    expected_reward = 0.5 + 0.5 * memory_relevance
    # â†’ U_{n,k} = U_0 + Î± * C_n(k)
    
    # 4. PFC Softmax
    pfc_result = self.pfc.process(actions)
    # â†’ P_n(k) = exp(Î² * U_{n,k}) / Î£ exp(Î² * U_{n,j})
    
    # 5. ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ê°€ëŠ¥)
    # E_n = -Î£ P_n(k) * ln(P_n(k))
```

---

## ğŸ“Š ìˆ˜ì‹ ì •ë¦¬ (ìµœì¢… í™•ì •ë³¸)

### ì™„ì „í•œ ëª¨ë¸

$$
\begin{align}
C_n(k) &= \min\left(1, \sum_{i} s_i \cdot m_{i,k}\right) \\
U_{n,k} &= U_0 + \alpha \cdot C_n(k) \\
P_n(k) &= \frac{\exp(\beta \cdot U_{n,k})}{\sum_j \exp(\beta \cdot U_{n,j})} \\
E_n &= -\sum_{k} P_n(k) \ln P_n(k)
\end{align}
$$

**ë³€ìˆ˜ ì •ì˜:**
- $s_i$: recall() ë°˜í™˜ ì¤‘ìš”ë„ (í˜„ì¬ MemoryRank score)
- $m_{i,k} \in [0,1]$: í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ë§¤ì¹­ (í˜„ì¬ í¬í•¨ ì—¬ë¶€ ê¸°ë°˜ ë¶„í•  ì ìˆ˜)
- $\beta = \text{decision\_temperature}$: Inverse-temperature
- $\alpha = 0.5$: ê¸°ì–µ ì˜í–¥ ê³„ìˆ˜ (í˜„ì¬ ì½”ë“œì—ì„  decide() ë‚´ë¶€ ìƒìˆ˜)
- $U_0 = 0.5$: ê¸°ë³¸ ë³´ìƒ (í˜„ì¬ ì½”ë“œì—ì„  decide() ë‚´ë¶€ ìƒìˆ˜)

---

## ğŸ¯ ëª¨ë“œë³„ ì—”íŠ¸ë¡œí”¼ ì˜ˆì¸¡

### ASD ëª¨ë“œ

$$
\beta = 5.0, \quad \alpha = 0.5
$$

**ì‹œë‚˜ë¦¬ì˜¤:** "red" ê´€ë ¨ ê¸°ì–µ 3ê°œ (s_i = 0.8, 0.7, 0.6)

$$
C_n(\text{choose\_red}) = \min(1, 0.8 \times 1.0 + 0.7 \times 1.0 + 0.6 \times 1.0) = 1.0
$$

$$
U_{n,\text{choose\_red}} = 0.5 + 0.5 \times 1.0 = 1.0
$$

$$
U_{n,\text{choose\_blue}} = U_{n,\text{choose\_green}} = 0.5 + 0.5 \times 0.0 = 0.5
$$

$$
P_n(\text{choose\_red}) \approx 0.99 \quad \text{(Î²=5.0ìœ¼ë¡œ ìˆ˜ë ´)}
$$

$$
E_n \approx -0.99 \ln(0.99) - 0.005 \ln(0.005) - 0.005 \ln(0.005) \approx 0.05
$$

**ê²°ê³¼:** $E_n \to 0$ (ì €ì—”íŠ¸ë¡œí”¼ ê³ ì°©) âœ…

---

### ADHD ëª¨ë“œ

$$
\beta = 0.5, \quad \alpha = 0.5
$$

**ë™ì¼í•œ ì‹œë‚˜ë¦¬ì˜¤:**

$$
U_{n,\text{choose\_red}} = 1.0, \quad U_{n,\text{choose\_blue}} = U_{n,\text{choose\_green}} = 0.5
$$

$$
P_n(\text{choose\_red}) \approx 0.38, \quad P_n(\text{choose\_blue}) \approx 0.31, \quad P_n(\text{choose\_green}) \approx 0.31
$$

$$
E_n \approx -0.38 \ln(0.38) - 0.31 \ln(0.31) - 0.31 \ln(0.31) \approx 1.08
$$

**ìµœëŒ€ ì—”íŠ¸ë¡œí”¼:** $\ln(3) \approx 1.10$

**ê²°ê³¼:** $E_n \to \ln(N)$ (ê³ ì—”íŠ¸ë¡œí”¼ ë°œì‚°) âœ…

---

## âš ï¸ ì •í™•í•œ êµ¬í˜„ ìƒíƒœ

### í˜„ì¬ êµ¬í˜„ë¨

1. âœ… $C_n(k)$ ê³„ì‚° (`_calculate_memory_relevance()`)
2. âœ… $U_{n,k}$ ê³„ì‚° (`decide()` ë©”ì„œë“œ)
3. âœ… $P_n(k)$ ê³„ì‚° (PFCEngine softmax)
4. âœ… $E_n$ ê³„ì‚° ê°€ëŠ¥ (ìˆ˜ì‹ìœ¼ë¡œ ê³„ì‚°)

### í˜„ì¬ ë¯¸êµ¬í˜„

1. âŒ BasalGangliaê°€ $P_n(k)$ì— ì§ì ‘ ê°œì…
   - í˜„ì¬ëŠ” `habit_suggestion` ì±„ë„ë¡œë§Œ ì˜í–¥
   - ì¶©ëŒ flagë¡œ ê´€ì°° ê°€ëŠ¥

2. âŒ Thalamus ê²Œì´íŒ… ë£¨í”„
   - `remember()`ê°€ Thalamusë¥¼ ê±°ì¹˜ì§€ ì•ŠìŒ

3. âŒ Hypothalamus í†µí•©
   - ì—ë„ˆì§€/ìŠ¤íŠ¸ë ˆìŠ¤ê°€ utilityì— ë°˜ì˜ë˜ì§€ ì•ŠìŒ

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [COGNITIVE_STATES.md](./COGNITIVE_STATES.md) - ëª¨ë“œë³„ ìƒì„¸ ì„¤ëª…
- [COGNITIVE_LOOPS_ANALYSIS.md](./COGNITIVE_LOOPS_ANALYSIS.md) - ë£¨í”„ ë¶„ì„
- [COGNITIVE_STATES_HONEST.md](./COGNITIVE_STATES_HONEST.md) - ì •ì§í•œ ê¸°ìˆ  ë¬¸ì„œ

---

**Author**: GNJz (Qquarts)  
**Version**: 2.0.1  
**Last Updated**: 2026-01-30

