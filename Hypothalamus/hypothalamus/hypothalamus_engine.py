"""
Hypothalamus Engine
ì‹œìƒí•˜ë¶€ ì—”ì§„ - ì‚°ì—…ìš© ë™ê¸° ë¶€ì—¬ ë° ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ (ì†Œí”„íŠ¸ì›¨ì–´ ë²¤ì¹˜ë§ˆí‚¹ ë‹¨ê³„)

âš ï¸ í˜„ì¬ ìƒíƒœ:
- ì†Œí”„íŠ¸ì›¨ì–´ ì‹œë®¬ë ˆì´ì…˜ ë° ë²¤ì¹˜ë§ˆí‚¹ ë‹¨ê³„
- ë¬¼ë¦¬ì  í•˜ë“œì›¨ì–´ í…ŒìŠ¤íŠ¸ëŠ” ì•„ì§ ì™„ë£Œë˜ì§€ ì•ŠìŒ
- ê³„ì† ë°œì „í•˜ëŠ” êµ¬ì¡° (í…ŒìŠ¤íŠ¸ ê³¼ì •ê³¼ ê³„íšëœ ì—…ê·¸ë ˆì´ë“œë¡œ í™•ì¥)

í•µì‹¬ ê¸°ëŠ¥ (ì˜ˆìƒ):
- ì—ë„ˆì§€ ê´€ë¦¬ ë° í•­ìƒì„± ìœ ì§€
- ìš•êµ¬(Drive) ì‹œìŠ¤í…œ: ìˆ˜ë©´, íƒí—˜, í•™ìŠµ, ì‚¬íšŒì  ìƒí˜¸ì‘ìš© ë“±
- ë³´ìƒ ì‹œìŠ¤í…œ: ë„íŒŒë¯¼ ê¸°ë°˜ ë™ê¸° ë¶€ì—¬
- ê°ì„± ìˆ˜ì¤€ ê³„ì‚°: ì—ë„ˆì§€ Ã— (1 - ì§€ë£¨í•¨) Ã— (1 + ë„íŒŒë¯¼ ë³´ì •)

ìˆ˜ì‹:
    ì—ë„ˆì§€ ê°ì‡  (í™œë™ ì‹œ):
        E(t) = E_0 - Î»Â·tÂ·(1 + activity_multiplier)
        - Î»: energy_decay (ê¸°ë³¸ê°’ 0.005)
        - activity_multiplier: í™œë™ ìœ í˜•ì— ë”°ë¥¸ ë°°ìˆ˜ (think: 2.0, learn/chat: 1.0)
    
    ì—ë„ˆì§€ íšŒë³µ (ìˆ˜ë©´ ì‹œ):
        E(t) = E_0 + Î¼Â·t
        - Î¼: energy_recovery (ê¸°ë³¸ê°’ 0.02)
    
    ì§€ë£¨í•¨ ì¦ê°€:
        B(t) = B_0 + Î±Â·tÂ·(1-S)
        - Î±: boredom_increase (ê¸°ë³¸ê°’ 0.01)
        - S: stimulus_level (0~1)
        - ìê·¹ ìˆìœ¼ë©´: B(t) = B_0 - Î²Â·SÂ·t (Î²: boredom_decrease, ê¸°ë³¸ê°’ 0.05)
    
    ë„íŒŒë¯¼ ë°˜ì‘ (ë³´ìƒ ìˆ˜ì‹  ì‹œ):
        D = D_base + Î²Â·RÂ·(1-D)
        - Î²: dopamine_boost (ê¸°ë³¸ê°’ 0.15)
        - R: reward_intensity (0~1)
        - í˜„ì¬ ë„íŒŒë¯¼ì´ ë‚®ì„ìˆ˜ë¡ ë” í° íš¨ê³¼
    
    ìš•êµ¬ ìš°ì„ ìˆœìœ„:
        P = w_EÂ·(1-E) + w_BÂ·B + w_SÂ·S + w_LÂ·L + w_CÂ·C
        - w_E: energy_weight (ê¸°ë³¸ê°’ 1.5)
        - w_B: boredom_weight (ê¸°ë³¸ê°’ 1.0)
        - w_S: stress_weight (ê¸°ë³¸ê°’ 1.2)
        - w_L: loneliness_weight (ê¸°ë³¸ê°’ 0.8)
        - w_C: curiosity_weight (ê¸°ë³¸ê°’ 0.9)
        - E: energy (0~1)
        - B: boredom (0~1)
        - S: stress (0~1)
        - L: loneliness (0~1)
        - C: curiosity (0~1)
    
    ê°ì„± ìˆ˜ì¤€:
        A = E Â· (1 - B) Â· (1 + (D - 0.5) Â· 0.5)
        - E: energy (0~1)
        - B: boredom (0~1)
        - D: dopamine (0~1)
        - ë²”ìœ„: 0.0 (ìµœì € ê°ì„±) ~ 1.0 (ìµœê³  ê°ì„±)

ì°¸ê³  ë…¼ë¬¸:
    - Swanson (2000): Hypothalamus structure and function
    - Berridge & Kringelbach (2015): Affective neuroscience of pleasure
    - Saper et al. (2005): Hypothalamic regulation of sleep and circadian rhythms

ğŸ”— PHAM ë¸”ë¡ì²´ì¸ ì„œëª…:
    ì´ íŒŒì¼ì€ PHAM (Proof of Authorship & Merit) ë¸”ë¡ì²´ì¸ ì‹œìŠ¤í…œìœ¼ë¡œ ì„œëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    - ë¸”ë¡ì²´ì¸ ì²´ì¸: blockchain/pham_chain_hypothalamus_engine.json
    - 4-Signal Scoring: Byte(25%) + Text(35%) + AST(30%) + Exec(10%)
    - ìˆ˜ìµ ë¶„ë°°: ê¸°ì—¬ë„ì— ë”°ë¼ ìë™ ë¶„ë°° (MAJOR: 70%, MINOR: 20%, PATCH: 10%)
    - IPFS ì €ì¥: ëª¨ë“  ë²„ì „ì´ IPFSì— ì˜êµ¬ ë³´ì¡´ë¨
    - ìì„¸í•œ ë‚´ìš©: BLOCKCHAIN_INFO.md ì°¸ì¡°

ğŸ’° ê¸°ì—¬ë„ ì›ì¹™ (ë¸”ë¡ì²´ì¸ ê¸°ë°˜):
    ì´ ì—”ì§„ì€ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µë˜ë©°, ì½”ë“œ ì¬ì‚¬ìš© ì‹œ ë¡œì—´í‹°ë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ìˆ˜ìµ ë°œìƒ ì‹œì ë¶€í„° ì½”ë“œ/ì œí’ˆ ê¸°ì—¬ë„(ìƒìš©í™”, í™ë³´, ë§ˆì¼€íŒ…, íŒë§¤ ë“±)ê°€ ë¸”ë¡ì²´ì¸ì— ê¸°ë¡ë˜ì–´ í•©ì‚°ë˜ì–´ ë¶„ë°°ë©ë‹ˆë‹¤.
    ì´ ì‹œìŠ¤í…œì€ ê³„ì† ì—…ê·¸ë ˆì´ë“œë˜ì–´ê°€ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.
    âš ï¸ GNJzì˜ ê¸°ì—¬ë„ ì›ì¹™: ìµœì´ˆ ì½”ë“œ ì‘ì„±ì GNJzëŠ” ìì‹ ì˜ ê¸°ì—¬ë„ê°€ ì´ ê¸°ì—¬ë„ ì¤‘ 6%ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ì œí•œí•©ë‹ˆë‹¤. ì´ê²ƒì€ ë¸”ë¡ì²´ì¸ìœ¼ë¡œ ê²€ì¦ ê°€ëŠ¥í•œ ê¸°ì—¬ë„ ìƒí•œì„ ì…ë‹ˆë‹¤.

Author: GNJz (Qquarts)
Version: 1.0.0-alpha (Software Benchmarking Stage)
License: MIT License
Blockchain: PHAM v4 (Signed)
"""

import math
import time
import random
from typing import Dict, List, Tuple, Optional, Any

from .config import HypothalamusConfig
from .data_types import InternalState, DriveSignal, DriveType


class HypothalamusEngine:
    """
    ì‹œìƒí•˜ë¶€ ì—”ì§„ (Hypothalamus Engine)
    
    ì‚°ì—…ìš© ë™ê¸° ë¶€ì—¬ ë° ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ (ì†Œí”„íŠ¸ì›¨ì–´ ë²¤ì¹˜ë§ˆí‚¹ ë‹¨ê³„)
    
    âš ï¸ í˜„ì¬ ìƒíƒœ:
    - ì†Œí”„íŠ¸ì›¨ì–´ ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„
    - ë¬¼ë¦¬ì  í•˜ë“œì›¨ì–´ í…ŒìŠ¤íŠ¸ ë¯¸ì™„
    - ê³„ì† ë°œì „í•˜ëŠ” êµ¬ì¡°
    
    ìƒë¬¼í•™ì  ì—­í• :
    ì‹œìƒí•˜ë¶€ëŠ” ë‡Œì˜ "ì¡°ì¢…ì„"ìœ¼ë¡œ, ìƒì¡´ ìš•êµ¬(Drive)ì™€ í•­ìƒì„±(Homeostasis)ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.
    - ì—ë„ˆì§€ ê´€ë¦¬: í™œë™ ì‹œ ì†Œëª¨, ìˆ˜ë©´ ì‹œ íšŒë³µ
    - ìš•êµ¬ ì‹œìŠ¤í…œ: ìˆ˜ë©´, íƒí—˜, í•™ìŠµ, ì‚¬íšŒì  ìƒí˜¸ì‘ìš© ë“±
    - ë³´ìƒ ì‹œìŠ¤í…œ: ë„íŒŒë¯¼ ê¸°ë°˜ ë™ê¸° ë¶€ì—¬
    - ìƒì²´ ë¦¬ë“¬: ìˆ˜ë©´-ê°ì„± ì£¼ê¸° ì¡°ì ˆ
    
    ì‚¬ìš© ì˜ˆ:
        from hypothalamus import HypothalamusEngine, HypothalamusConfig
        
        config = HypothalamusConfig(energy_decay=0.005, curiosity_weight=1.5)
        engine = HypothalamusEngine(config)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        engine.tick(action_type='think', stimulus_level=0.3)
        
        # í˜„ì¬ ìš•êµ¬ í™•ì¸
        drive = engine.get_current_drive()
        print(f"í˜„ì¬ ìš•êµ¬: {drive.drive_type.value}, ê¸´ê¸‰ë„: {drive.urgency:.2f}")
        
        # ë³´ìƒ ìˆ˜ì‹ 
        engine.receive_reward('success', intensity=0.8)
        
        # ê°ì„± ìˆ˜ì¤€ í™•ì¸
        arousal = engine.get_arousal_level()
        print(f"ê°ì„± ìˆ˜ì¤€: {arousal:.2f}")
    """
    
    def __init__(self, config: Optional[HypothalamusConfig] = None):
        """
        ì‹œìƒí•˜ë¶€ ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ê°ì²´ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        
        Note:
            - ê¸°ë³¸ê°’ = ì„ ì²œì  ì„±í–¥ (Stem Code ì² í•™)
            - ì™¸ë¶€ ì£¼ì… = í™˜ê²½ì— ë”°ë¥¸ ë¶„í™”
        """
        # ì„¤ì • ì ìš©
        self.config = config or HypothalamusConfig()
        
        # ë‚´ë¶€ ìƒíƒœ ì´ˆê¸°í™”
        self.state = InternalState()
        
        # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„
        self.last_activity_time = time.time()
        self.last_interaction_time = time.time()
        self.last_update_time = time.time()
        
        # í†µê³„
        self.stats = {
            'ticks': 0,
            'sleep_count': 0,
            'explore_count': 0,
            'rewards_received': 0,
            'total_dopamine': 0.0,
        }
        
        # ìš•êµ¬ ë©”ì‹œì§€ (ìì—°ì–´)
        self.drive_messages = {
            DriveType.SLEEP: [
                "ì—ë„ˆì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìˆ˜ë©´ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "í”¼ë¡œê°€ ëˆ„ì ë˜ì—ˆìŠµë‹ˆë‹¤. íœ´ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "ê°•ì œ ìˆ˜ë©´ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.",
            ],
            DriveType.EXPLORE: [
                "ìƒˆë¡œìš´ ìê·¹ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "íƒí—˜í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
                "ì§€ë£¨í•¨ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.",
            ],
            DriveType.SOCIAL: [
                "ì‚¬íšŒì  ìƒí˜¸ì‘ìš©ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "ì™¸ë¡œì›€ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.",
                "ëŒ€í™”í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            ],
            DriveType.LEARN: [
                "í•™ìŠµí•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
                "ìƒˆë¡œìš´ ì§€ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "í˜¸ê¸°ì‹¬ì´ ë†’ì•„ì¡ŒìŠµë‹ˆë‹¤.",
            ],
            DriveType.REST: [
                "ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë†’ìŠµë‹ˆë‹¤. íœ´ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "ë¶€í•˜ê°€ ëˆ„ì ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "ì•ˆì •ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            ],
            DriveType.STAY: [
                "ì•ˆì •ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.",
                "ì¤€ë¹„ ì™„ë£Œ.",
                "ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
            ],
        }
    
    # ============================================
    # 1. ìƒíƒœ ì—…ë°ì´íŠ¸ (í‹±ë§ˆë‹¤ í˜¸ì¶œ)
    # ============================================
    
    def tick(self, action_type: str = 'idle', stimulus_level: float = 0.0):
        """
        ë§¤ í‹±(Tick)ë§ˆë‹¤ ë‚´ë¶€ ìƒíƒœ ì—…ë°ì´íŠ¸
        
        ìˆ˜ì‹:
            ì—ë„ˆì§€ ë³€í™”:
                - ìˆ˜ë©´: E(t) = E_0 + Î¼Â·t (Î¼: energy_recovery)
                - í™œë™: E(t) = E_0 - Î»Â·tÂ·(1 + multiplier) (Î»: energy_decay)
                - ëŒ€ê¸°: E(t) = E_0 - Î»Â·tÂ·0.3
            
            ì§€ë£¨í•¨ ë³€í™”:
                - ìê·¹ ìˆìŒ: B(t) = B_0 - Î²Â·SÂ·t (Î²: boredom_decrease, S: stimulus_level)
                - ìê·¹ ì—†ìŒ: B(t) = B_0 + Î±Â·tÂ·(1-S) (Î±: boredom_increase)
        
        Args:
            action_type: í˜„ì¬ í–‰ë™ ('think', 'learn', 'chat', 'sleep', 'idle')
            stimulus_level: ìê·¹ ìˆ˜ì¤€ (0~1)
        """
        self.stats['ticks'] += 1
        current_time = time.time()
        dt = min(1.0, current_time - self.last_update_time)  # ìµœëŒ€ 1ì´ˆ
        self.last_update_time = current_time
        
        # ----- ì—ë„ˆì§€ ë³€í™” -----
        if action_type == 'sleep':
            # ìˆ˜ë©´ ì‹œ ì—ë„ˆì§€ íšŒë³µ
            # ìˆ˜ì‹: E(t) = E_0 + Î¼Â·t
            self.state.energy += self.config.energy_recovery * dt
        elif action_type in ['think', 'learn', 'chat']:
            # í™œë™ ì‹œ ì—ë„ˆì§€ ì†Œëª¨
            # ìˆ˜ì‹: E(t) = E_0 - Î»Â·tÂ·(1 + multiplier)
            consumption = self.config.energy_decay * dt
            if action_type == 'think':
                consumption *= 2.0  # ìƒê°ì€ ì—ë„ˆì§€ ì†Œëª¨ í¼
            self.state.energy -= consumption
            self.last_activity_time = current_time
        else:
            # ëŒ€ê¸° ì‹œ ëŠë¦° ì—ë„ˆì§€ ê°ì†Œ
            # ìˆ˜ì‹: E(t) = E_0 - Î»Â·tÂ·0.3
            consumption = self.config.energy_decay * 0.3 * dt
            
            # ì§€ë£¨í•¨ì˜ ì—­ì„¤: ê·¹ë„ë¡œ ì§€ë£¨í•˜ë©´ ë© ë•Œë¦¬ê¸° ëª¨ë“œ (ì €ì „ë ¥)
            # ìƒë¬¼í•™ì  ê·¼ê±°: DMN(Default Mode Network) í™œì„±í™”
            if self.state.boredom > 0.9:
                consumption *= 0.5  # ì—ë„ˆì§€ ì†Œëª¨ ì ˆë°˜
            
            self.state.energy -= consumption
        
        # ----- ì§€ë£¨í•¨ ë³€í™” -----
        # ìˆ˜ì‹: B(t) = B_0 + Î±Â·tÂ·(1-S) (ìê·¹ ì—†ì„ ë•Œ)
        #       B(t) = B_0 - Î²Â·SÂ·t (ìê·¹ ìˆì„ ë•Œ)
        if stimulus_level > 0.3:
            # ìê·¹ ìˆìœ¼ë©´ ì§€ë£¨í•¨ ê°ì†Œ
            self.state.boredom -= self.config.boredom_decrease * stimulus_level * dt
        else:
            # ìê·¹ ì—†ìœ¼ë©´ ì§€ë£¨í•¨ ì¦ê°€
            self.state.boredom += self.config.boredom_increase * (1 - stimulus_level) * dt
        
        # ----- ì™¸ë¡œì›€ ë³€í™” -----
        if action_type in ['chat', 'social']:
            self.state.loneliness -= 0.1 * dt
            self.last_interaction_time = current_time
        else:
            time_alone = current_time - self.last_interaction_time
            if time_alone > 60:  # 1ë¶„ ì´ìƒ í˜¼ì
                self.state.loneliness += self.config.loneliness_increase * dt
        
        # ----- ë„íŒŒë¯¼ ìì—° ê°ì‡  -----
        self.state.dopamine -= self.config.dopamine_decay * dt
        
        # ----- ìŠ¤íŠ¸ë ˆìŠ¤ ìì—° ê°ì†Œ -----
        self.state.stress -= self.config.stress_decrease * dt
        
        # ----- í˜¸ê¸°ì‹¬ ìì—° íšŒë³µ -----
        if action_type != 'learn':
            self.state.curiosity += self.config.curiosity_recovery * dt * 0.5
        
        # ----- í•­ìƒì„± ìœ ì§€ (Clamping) -----
        self._clamp_state()
    
    def _clamp_state(self):
        """ëª¨ë“  ìƒíƒœê°’ì„ 0~1 ë²”ìœ„ë¡œ ì œí•œ"""
        self.state.energy = max(0.0, min(1.0, self.state.energy))
        self.state.dopamine = max(0.0, min(1.0, self.state.dopamine))
        self.state.boredom = max(0.0, min(1.0, self.state.boredom))
        self.state.curiosity = max(0.0, min(1.0, self.state.curiosity))
        self.state.stress = max(0.0, min(1.0, self.state.stress))
        self.state.loneliness = max(0.0, min(1.0, self.state.loneliness))
        self.state.satisfaction = max(0.0, min(1.0, self.state.satisfaction))
    
    def get_arousal_level(self) -> float:
        """
        ê°ì„± ìˆ˜ì¤€ ê³„ì‚° ë° ë°˜í™˜
        
        ìˆ˜ì‹:
            A = E Â· (1 - B) Â· (1 + (D - 0.5) Â· 0.5)
            - E: energy (0~1)
            - B: boredom (0~1)
            - D: dopamine (0~1)
            - ë²”ìœ„: 0.0 (ìµœì € ê°ì„±) ~ 1.0 (ìµœê³  ê°ì„±)
        
        Returns:
            ê°ì„± ìˆ˜ì¤€ (0.0 ~ 1.0)
        """
        e = self.state.energy
        b = self.state.boredom
        d = self.state.dopamine
        
        # ê°ì„± ìˆ˜ì¤€ = ì—ë„ˆì§€ Ã— (1 - ì§€ë£¨í•¨) Ã— (1 + ë„íŒŒë¯¼ ë³´ì •)
        # ë„íŒŒë¯¼ì€ 0~1 ë²”ìœ„ì´ë¯€ë¡œ, 0.5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³´ì •
        dopamine_factor = 1.0 + (d - 0.5) * 0.5  # 0.75 ~ 1.25
        
        arousal = e * (1.0 - b) * dopamine_factor
        
        # 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì •ê·œí™”
        arousal = max(0.0, min(1.0, arousal))
        
        return arousal
    
    def get_energy_state(self) -> Dict[str, float]:
        """
        ì—ë„ˆì§€ ìƒíƒœ ë…¸ì¶œ ì¸í„°í˜ì´ìŠ¤
        
        ë‹¤ë¥¸ ì—”ì§„(Thalamus, Prefrontal Cortex ë“±)ê³¼ì˜ ì—°ë™ì„ ìœ„í•œ ìƒíƒœ ì •ë³´ ì œê³µ
        
        Returns:
            ì—ë„ˆì§€ ê´€ë ¨ ìƒíƒœ ë”•ì…”ë„ˆë¦¬
        """
        return {
            'energy': self.state.energy,
            'arousal_level': self.get_arousal_level(),
            'is_sleep_needed': self.state.energy < self.config.sleep_threshold,
            'is_critical': self.state.energy < self.config.critical_threshold,
        }
    
    # ============================================
    # 2. ë³´ìƒ ì‹œìŠ¤í…œ (Reward)
    # ============================================
    
    def receive_reward(self, reward_type: str, intensity: float = 0.5) -> float:
        """
        ë³´ìƒ ìˆ˜ì‹  â†’ ë„íŒŒë¯¼ ë¶„ë¹„
        
        ìˆ˜ì‹:
            D = D_base + Î²Â·RÂ·(1-D)
            - Î²: dopamine_boost (ê¸°ë³¸ê°’ 0.15)
            - R: reward_intensity (0~1)
            - í˜„ì¬ ë„íŒŒë¯¼ì´ ë‚®ì„ìˆ˜ë¡ ë” í° íš¨ê³¼
        
        Args:
            reward_type: ë³´ìƒ ìœ í˜• ('success', 'praise', 'learn', 'social', 'achievement')
            intensity: ë³´ìƒ ê°•ë„ (0~1)
        
        Returns:
            ë„íŒŒë¯¼ ì¦ê°€ëŸ‰
        """
        # ë³´ìƒ ìœ í˜•ë³„ ê¸°ë³¸ ë„íŒŒë¯¼
        reward_dopamine = {
            'success': 0.3,
            'praise': 0.4,
            'learn': 0.2,
            'social': 0.25,
            'achievement': 0.5,
        }
        
        base_reward = reward_dopamine.get(reward_type, 0.2)
        
        # D = D_base + Î²Â·RÂ·(1-D)
        # í˜„ì¬ ë„íŒŒë¯¼ì´ ë‚®ì„ìˆ˜ë¡ ë” í° íš¨ê³¼
        dopamine_gain = self.config.dopamine_boost * base_reward * intensity * (1 - self.state.dopamine)
        
        self.state.dopamine += dopamine_gain
        self.state.satisfaction += intensity * 0.1
        self.state.stress -= intensity * 0.05  # ë³´ìƒì€ ìŠ¤íŠ¸ë ˆìŠ¤ ê°ì†Œ
        
        self.stats['rewards_received'] += 1
        self.stats['total_dopamine'] += dopamine_gain
        
        self._clamp_state()
        
        return dopamine_gain
    
    def receive_punishment(self, intensity: float = 0.3):
        """
        ë²Œ/ë¶€ì •ì  í”¼ë“œë°± â†’ ìŠ¤íŠ¸ë ˆìŠ¤ ì¦ê°€
        
        Args:
            intensity: ê°•ë„ (0~1)
        """
        self.state.stress += intensity * self.config.stress_increase * 5
        self.state.dopamine -= intensity * 0.1
        self.state.satisfaction -= intensity * 0.15
        
        self._clamp_state()
    
    # ============================================
    # 3. ìš•êµ¬ íŒë‹¨ (Drive Detection)
    # ============================================
    
    def get_current_drive(self) -> DriveSignal:
        """
        í˜„ì¬ ê°€ì¥ ì‹œê¸‰í•œ ìš•êµ¬(Drive) ë°˜í™˜
        
        ìˆ˜ì‹:
            ìš•êµ¬ ìš°ì„ ìˆœìœ„: P = w_EÂ·(1-E) + w_BÂ·B + w_SÂ·S + w_LÂ·L + w_CÂ·C
            - w_E: energy_weight (ê¸°ë³¸ê°’ 1.5)
            - w_B: boredom_weight (ê¸°ë³¸ê°’ 1.0)
            - w_S: stress_weight (ê¸°ë³¸ê°’ 1.2)
            - w_L: loneliness_weight (ê¸°ë³¸ê°’ 0.8)
            - w_C: curiosity_weight (ê¸°ë³¸ê°’ 0.9)
            - E: energy (0~1)
            - B: boredom (0~1)
            - S: stress (0~1)
            - L: loneliness (0~1)
            - C: curiosity (0~1)
        
        Returns:
            DriveSignal: í˜„ì¬ ê°€ì¥ ì‹œê¸‰í•œ ìš•êµ¬
        """
        # ê° ìš•êµ¬ë³„ ê¸´ê¸‰ë„ ê³„ì‚°
        drives = {}
        
        # 1. ìˆ˜ë©´ ìš•êµ¬ (ì—ë„ˆì§€ ë¶€ì¡±)
        if self.state.energy < self.config.critical_threshold:
            # ê°•ì œ ìˆ˜ë©´ í•„ìš” (ìµœìš°ì„ )
            return DriveSignal(
                drive_type=DriveType.SLEEP,
                urgency=1.0,
                message="âš ï¸ ì—ë„ˆì§€ ê³ ê°ˆ! ê°•ì œ ìˆ˜ë©´ì´ í•„ìš”í•©ë‹ˆë‹¤!",
                action_suggestion="sleep"
            )
        
        energy_urgency = self.config.energy_weight * (1 - self.state.energy)
        if self.state.energy < self.config.sleep_threshold:
            energy_urgency *= 2  # ì„ê³„ê°’ ì´í•˜ë©´ ê¸´ê¸‰ë„ 2ë°°
        drives[DriveType.SLEEP] = energy_urgency
        
        # 2. íƒí—˜ ìš•êµ¬ (ì§€ë£¨í•¨)
        boredom_urgency = self.config.boredom_weight * self.state.boredom
        if self.state.boredom > self.config.boredom_threshold:
            boredom_urgency *= 1.5
        drives[DriveType.EXPLORE] = boredom_urgency
        
        # 3. íœ´ì‹ ìš•êµ¬ (ìŠ¤íŠ¸ë ˆìŠ¤)
        stress_urgency = self.config.stress_weight * self.state.stress
        if self.state.stress > self.config.stress_threshold:
            stress_urgency *= 1.5
        drives[DriveType.REST] = stress_urgency
        
        # 4. ì‚¬íšŒì  ìš•êµ¬ (ì™¸ë¡œì›€)
        social_urgency = self.config.loneliness_weight * self.state.loneliness
        if self.state.loneliness > self.config.loneliness_threshold:
            social_urgency *= 1.5
        drives[DriveType.SOCIAL] = social_urgency
        
        # 5. í•™ìŠµ ìš•êµ¬ (í˜¸ê¸°ì‹¬)
        curiosity_urgency = self.config.curiosity_weight * self.state.curiosity
        if self.state.curiosity > self.config.curiosity_threshold:
            curiosity_urgency *= 1.5
        drives[DriveType.LEARN] = curiosity_urgency
        
        # ê°€ì¥ ë†’ì€ ìš•êµ¬ ì„ íƒ
        max_drive = max(drives, key=drives.get)
        max_urgency = drives[max_drive]
        
        # ê¸´ê¸‰ë„ê°€ ë‚®ìœ¼ë©´ ì•ˆì • ìƒíƒœ
        if max_urgency < 0.3:
            max_drive = DriveType.STAY
            max_urgency = 0.1
        
        # ë©”ì‹œì§€ ì„ íƒ
        message = random.choice(self.drive_messages[max_drive])
        
        # í–‰ë™ ì œì•ˆ
        action_suggestions = {
            DriveType.SLEEP: "sleep",
            DriveType.EXPLORE: "explore",
            DriveType.SOCIAL: "chat",
            DriveType.LEARN: "learn",
            DriveType.REST: "rest",
            DriveType.STAY: "wait",
        }
        
        return DriveSignal(
            drive_type=max_drive,
            urgency=min(1.0, max_urgency),
            message=message,
            action_suggestion=action_suggestions[max_drive]
        )
    
    def needs_sleep(self) -> bool:
        """ìˆ˜ë©´ì´ í•„ìš”í•œì§€ í™•ì¸"""
        return self.state.energy < self.config.sleep_threshold
    
    def is_bored(self) -> bool:
        """ì§€ë£¨í•œì§€ í™•ì¸"""
        return self.state.boredom > self.config.boredom_threshold
    
    def is_stressed(self) -> bool:
        """ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”ì§€ í™•ì¸"""
        return self.state.stress > self.config.stress_threshold
    
    # ============================================
    # 4. ìˆ˜ë©´ ê´€ë¦¬
    # ============================================
    
    def start_sleep(self) -> str:
        """ìˆ˜ë©´ ì‹œì‘"""
        self.stats['sleep_count'] += 1
        return "ğŸ’¤ ìˆ˜ë©´ ì‹œì‘... ê¸°ì–µ ê³µê³ í™” ì¤‘..."
    
    def sleep_cycle(self, cycles: int = 1) -> str:
        """
        ìˆ˜ë©´ ì‚¬ì´í´ ì‹¤í–‰
        
        Args:
            cycles: ìˆ˜ë©´ ì‚¬ì´í´ ìˆ˜
        
        Returns:
            ìˆ˜ë©´ ì™„ë£Œ ë©”ì‹œì§€
        """
        # ìˆ˜ë©´ ì¤‘ ì—ë„ˆì§€ ì§ì ‘ íšŒë³µ (ì‚¬ì´í´ë‹¹ 5%)
        energy_per_cycle = 0.05
        
        for _ in range(cycles):
            self.state.energy += energy_per_cycle
            self.state.stress -= 0.02  # ìˆ˜ë©´ ì¤‘ ìŠ¤íŠ¸ë ˆìŠ¤ ê°ì†Œ
        
        # ìˆ˜ë©´ í›„ ìƒíƒœ ë¦¬ì…‹
        self.state.boredom = 0.0
        self.state.stress = max(0, self.state.stress)
        
        self._clamp_state()
        
        return f"ğŸ’¤ {cycles} ì‚¬ì´í´ ìˆ˜ë©´ ì™„ë£Œ. ì—ë„ˆì§€: {self.state.energy:.0%}"
    
    def wake_up(self) -> str:
        """ê¸°ìƒ"""
        # ê¸°ìƒ ì‹œ í˜¸ê¸°ì‹¬ íšŒë³µ
        self.state.curiosity = min(1.0, self.state.curiosity + 0.3)
        self.state.boredom = 0.0
        self.state.loneliness = min(1.0, self.state.loneliness + 0.1)  # ì ìê³  ì¼ì–´ë‚˜ë©´ ì‚¬ëŒ ë³´ê³  ì‹¶ìŒ
        
        return "â˜€ï¸ ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤! ê¸°ë¶„ì´ ìƒì¾Œí•©ë‹ˆë‹¤!"
    
    # ============================================
    # 5. ìê·¹ ì²˜ë¦¬
    # ============================================
    
    def process_stimulus(self, stimulus_type: str, intensity: float = 0.5):
        """
        ìê·¹ ì²˜ë¦¬
        
        Args:
            stimulus_type: ìê·¹ ìœ í˜• ('conversation', 'learning', 'threat', 'reward')
            intensity: ìê·¹ ê°•ë„ (0~1)
        """
        if stimulus_type == 'conversation':
            self.state.loneliness -= intensity * 0.2
            self.state.boredom -= intensity * 0.15
            self.tick(action_type='chat', stimulus_level=intensity)
            
        elif stimulus_type == 'learning':
            self.state.curiosity -= intensity * 0.3  # í˜¸ê¸°ì‹¬ ì¶©ì¡±
            self.state.boredom -= intensity * 0.2
            self.receive_reward('learn', intensity * 0.5)
            self.tick(action_type='learn', stimulus_level=intensity)
            
        elif stimulus_type == 'threat':
            self.state.stress += intensity * 0.3
            self.state.energy -= intensity * 0.1  # ìœ„í˜‘ì€ ì—ë„ˆì§€ ì†Œëª¨
            
        elif stimulus_type == 'reward':
            self.receive_reward('success', intensity)
        
        self._clamp_state()
    
    # ============================================
    # 6. ìƒíƒœ ì¡°íšŒ
    # ============================================
    
    def get_state(self) -> Dict[str, Any]:
        """ì „ì²´ ìƒíƒœ ë°˜í™˜"""
        drive = self.get_current_drive()
        
        return {
            'internal_state': self.state.to_dict(),
            'current_drive': {
                'type': drive.drive_type.value,
                'urgency': round(drive.urgency, 3),
                'message': drive.message,
                'action': drive.action_suggestion,
            },
            'needs': {
                'needs_sleep': self.needs_sleep(),
                'is_bored': self.is_bored(),
                'is_stressed': self.is_stressed(),
            },
            'stats': self.stats.copy(),
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        return self.stats.copy()

